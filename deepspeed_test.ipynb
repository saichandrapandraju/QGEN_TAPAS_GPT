{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "deepspeed_test.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyOEb3OCvKYDSpROGGnTbBQB",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/saichandrapandraju/QGEN_TAPAS_GPT/blob/main/deepspeed_test.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vmqBo1dbEvHY",
        "outputId": "17092729-87f4-4365-9e1c-7574a8a516d3"
      },
      "source": [
        "!nvidia-smi"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Thu Mar 25 02:30:20 2021       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 460.56       Driver Version: 460.32.03    CUDA Version: 11.2     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                               |                      |               MIG M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla P100-PCIE...  Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   36C    P0    26W / 250W |      0MiB / 16280MiB |      0%      Default |\n",
            "|                               |                      |                  N/A |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                                  |\n",
            "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
            "|        ID   ID                                                   Usage      |\n",
            "|=============================================================================|\n",
            "|  No running processes found                                                 |\n",
            "+-----------------------------------------------------------------------------+\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2rRBCxnzEoTx",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "649fba07-0742-4689-f46f-95afc5987a95"
      },
      "source": [
        "!nvcc --version"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "nvcc: NVIDIA (R) Cuda compiler driver\n",
            "Copyright (c) 2005-2020 NVIDIA Corporation\n",
            "Built on Wed_Jul_22_19:09:09_PDT_2020\n",
            "Cuda compilation tools, release 11.0, V11.0.221\n",
            "Build cuda_11.0_bu.TC445_37.28845127_0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "21tYFkB9EeVG",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "51f9cdb0-83e5-4793-b3e7-cb34d069528c"
      },
      "source": [
        "!pip uninstall torch torchvision -y"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Uninstalling torch-1.8.0+cu101:\n",
            "  Successfully uninstalled torch-1.8.0+cu101\n",
            "Uninstalling torchvision-0.9.0+cu101:\n",
            "  Successfully uninstalled torchvision-0.9.0+cu101\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "v1iPybN-9y8G",
        "outputId": "633db5c1-88fd-4976-a050-83b356a6fb8e"
      },
      "source": [
        "!pip install torch==1.7.1+cu110 torchvision==0.8.2+cu110 -f https://download.pytorch.org/whl/torch_stable.html"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Looking in links: https://download.pytorch.org/whl/torch_stable.html\n",
            "Collecting torch==1.7.1+cu110\n",
            "\u001b[?25l  Downloading https://download.pytorch.org/whl/cu110/torch-1.7.1%2Bcu110-cp37-cp37m-linux_x86_64.whl (1156.8MB)\n",
            "\u001b[K     |███████████████████████         | 834.1MB 1.3MB/s eta 0:04:08tcmalloc: large alloc 1147494400 bytes == 0x55d810986000 @  0x7f4247536615 0x55d7d6cc806c 0x55d7d6da7eba 0x55d7d6ccae8d 0x55d7d6dbc99d 0x55d7d6d3efe9 0x55d7d6d39b0e 0x55d7d6ccc77a 0x55d7d6d3ee50 0x55d7d6d39b0e 0x55d7d6ccc77a 0x55d7d6d3b86a 0x55d7d6dbd7c6 0x55d7d6d3aee2 0x55d7d6dbd7c6 0x55d7d6d3aee2 0x55d7d6dbd7c6 0x55d7d6d3aee2 0x55d7d6dbd7c6 0x55d7d6e3f431 0x55d7d6da0049 0x55d7d6d0ac84 0x55d7d6ccb8e9 0x55d7d6d3fade 0x55d7d6ccc69a 0x55d7d6d3aa45 0x55d7d6d39e0d 0x55d7d6ccc77a 0x55d7d6d3aa45 0x55d7d6ccc69a 0x55d7d6d3aa45\n",
            "\u001b[K     |█████████████████████████████▏  | 1055.7MB 1.3MB/s eta 0:01:20tcmalloc: large alloc 1434370048 bytes == 0x55d854fdc000 @  0x7f4247536615 0x55d7d6cc806c 0x55d7d6da7eba 0x55d7d6ccae8d 0x55d7d6dbc99d 0x55d7d6d3efe9 0x55d7d6d39b0e 0x55d7d6ccc77a 0x55d7d6d3ee50 0x55d7d6d39b0e 0x55d7d6ccc77a 0x55d7d6d3b86a 0x55d7d6dbd7c6 0x55d7d6d3aee2 0x55d7d6dbd7c6 0x55d7d6d3aee2 0x55d7d6dbd7c6 0x55d7d6d3aee2 0x55d7d6dbd7c6 0x55d7d6e3f431 0x55d7d6da0049 0x55d7d6d0ac84 0x55d7d6ccb8e9 0x55d7d6d3fade 0x55d7d6ccc69a 0x55d7d6d3aa45 0x55d7d6d39e0d 0x55d7d6ccc77a 0x55d7d6d3aa45 0x55d7d6ccc69a 0x55d7d6d3aa45\n",
            "\u001b[K     |████████████████████████████████| 1156.7MB 1.1MB/s eta 0:00:01tcmalloc: large alloc 1445945344 bytes == 0x55d8aa7c8000 @  0x7f4247536615 0x55d7d6cc806c 0x55d7d6da7eba 0x55d7d6ccae8d 0x55d7d6dbc99d 0x55d7d6d3efe9 0x55d7d6d39b0e 0x55d7d6ccc77a 0x55d7d6d3ac9e 0x55d7d6d39b0e 0x55d7d6ccc77a 0x55d7d6d3ac9e 0x55d7d6d39b0e 0x55d7d6ccc77a 0x55d7d6d3ac9e 0x55d7d6d39b0e 0x55d7d6ccc77a 0x55d7d6d3ac9e 0x55d7d6d39b0e 0x55d7d6ccc77a 0x55d7d6d3ac9e 0x55d7d6ccc69a 0x55d7d6d3ac9e 0x55d7d6d39b0e 0x55d7d6ccc77a 0x55d7d6d3b86a 0x55d7d6d39b0e 0x55d7d6ccc77a 0x55d7d6d3b86a 0x55d7d6d39b0e 0x55d7d6ccce11\n",
            "\u001b[K     |████████████████████████████████| 1156.8MB 12kB/s \n",
            "\u001b[?25hCollecting torchvision==0.8.2+cu110\n",
            "\u001b[?25l  Downloading https://download.pytorch.org/whl/cu110/torchvision-0.8.2%2Bcu110-cp37-cp37m-linux_x86_64.whl (12.9MB)\n",
            "\u001b[K     |████████████████████████████████| 12.9MB 244kB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from torch==1.7.1+cu110) (1.19.5)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch==1.7.1+cu110) (3.7.4.3)\n",
            "Requirement already satisfied: pillow>=4.1.1 in /usr/local/lib/python3.7/dist-packages (from torchvision==0.8.2+cu110) (7.0.0)\n",
            "\u001b[31mERROR: torchtext 0.9.0 has requirement torch==1.8.0, but you'll have torch 1.7.1+cu110 which is incompatible.\u001b[0m\n",
            "Installing collected packages: torch, torchvision\n",
            "Successfully installed torch-1.7.1+cu110 torchvision-0.8.2+cu110\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ceaZmHGy92EQ",
        "outputId": "a5a05cc1-c592-4502-d39a-c61906c5f098"
      },
      "source": [
        "!pip install deepspeed==0.3.13"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting deepspeed==0.3.13\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/9a/fe/e49e41a5650952e693abdaef80ec97addec2c061632f978c213d2adb3b7c/deepspeed-0.3.13.tar.gz (334kB)\n",
            "\u001b[K     |████████████████████████████████| 337kB 8.4MB/s \n",
            "\u001b[?25hRequirement already satisfied: torch>=1.2 in /usr/local/lib/python3.7/dist-packages (from deepspeed==0.3.13) (1.7.1+cu110)\n",
            "Requirement already satisfied: torchvision>=0.4.0 in /usr/local/lib/python3.7/dist-packages (from deepspeed==0.3.13) (0.8.2+cu110)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from deepspeed==0.3.13) (4.41.1)\n",
            "Collecting tensorboardX==1.8\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/c3/12/dcaf67e1312475b26db9e45e7bb6f32b540671a9ee120b3a72d9e09bc517/tensorboardX-1.8-py2.py3-none-any.whl (216kB)\n",
            "\u001b[K     |████████████████████████████████| 225kB 8.5MB/s \n",
            "\u001b[?25hCollecting ninja\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/1d/de/393468f2a37fc2c1dc3a06afc37775e27fde2d16845424141d4da62c686d/ninja-1.10.0.post2-py3-none-manylinux1_x86_64.whl (107kB)\n",
            "\u001b[K     |████████████████████████████████| 112kB 14.7MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from deepspeed==0.3.13) (1.19.5)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.7/dist-packages (from deepspeed==0.3.13) (5.4.8)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch>=1.2->deepspeed==0.3.13) (3.7.4.3)\n",
            "Requirement already satisfied: pillow>=4.1.1 in /usr/local/lib/python3.7/dist-packages (from torchvision>=0.4.0->deepspeed==0.3.13) (7.0.0)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from tensorboardX==1.8->deepspeed==0.3.13) (1.15.0)\n",
            "Requirement already satisfied: protobuf>=3.2.0 in /usr/local/lib/python3.7/dist-packages (from tensorboardX==1.8->deepspeed==0.3.13) (3.12.4)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from protobuf>=3.2.0->tensorboardX==1.8->deepspeed==0.3.13) (54.1.2)\n",
            "Building wheels for collected packages: deepspeed\n",
            "  Building wheel for deepspeed (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for deepspeed: filename=deepspeed-0.3.13-cp37-none-any.whl size=328698 sha256=a55d523209adebff36df5eb074b8254385937e0799fa2a2a3815cf4c4fa36d46\n",
            "  Stored in directory: /root/.cache/pip/wheels/f7/52/b2/300b86ae75a4c074a379351c1fb224309c2a04e2e86ea64952\n",
            "Successfully built deepspeed\n",
            "Installing collected packages: tensorboardX, ninja, deepspeed\n",
            "Successfully installed deepspeed-0.3.13 ninja-1.10.0.post2 tensorboardX-1.8\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wbm_13FG95eg",
        "outputId": "684e9a70-7ef6-4f1a-8194-baf4c589c9f6"
      },
      "source": [
        "%%bash\n",
        "git clone https://github.com/huggingface/transformers\n",
        "cd transformers\n",
        "# examples change a lot so let's pick a sha that we know this notebook will work with\n",
        "# comment out/remove the next line if you want the master\n",
        "git checkout 1aa9c13f70ae75be7fd6\n",
        "pip install -e .\n",
        "pip install -r examples/_tests_requirements.txt\n",
        "\n",
        "# if needed free up some space used by cached pip packages\n",
        "# rm -rf /root/.cache/pip"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Obtaining file:///content/transformers\n",
            "  Installing build dependencies: started\n",
            "  Installing build dependencies: finished with status 'done'\n",
            "  Getting requirements to build wheel: started\n",
            "  Getting requirements to build wheel: finished with status 'done'\n",
            "    Preparing wheel metadata: started\n",
            "    Preparing wheel metadata: finished with status 'done'\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.7/dist-packages (from transformers==4.4.0.dev0) (1.19.5)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.7/dist-packages (from transformers==4.4.0.dev0) (4.41.1)\n",
            "Requirement already satisfied: importlib-metadata; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from transformers==4.4.0.dev0) (3.7.2)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers==4.4.0.dev0) (2.23.0)\n",
            "Collecting tokenizers<0.11,>=0.10.1\n",
            "  Downloading https://files.pythonhosted.org/packages/71/23/2ddc317b2121117bf34dd00f5b0de194158f2a44ee2bf5e47c7166878a97/tokenizers-0.10.1-cp37-cp37m-manylinux2010_x86_64.whl (3.2MB)\n",
            "Collecting sacremoses\n",
            "  Downloading https://files.pythonhosted.org/packages/7d/34/09d19aff26edcc8eb2a01bed8e98f13a1537005d31e95233fd48216eed10/sacremoses-0.0.43.tar.gz (883kB)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers==4.4.0.dev0) (2019.12.20)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from transformers==4.4.0.dev0) (20.9)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers==4.4.0.dev0) (3.0.12)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata; python_version < \"3.8\"->transformers==4.4.0.dev0) (3.4.1)\n",
            "Requirement already satisfied: typing-extensions>=3.6.4; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from importlib-metadata; python_version < \"3.8\"->transformers==4.4.0.dev0) (3.7.4.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers==4.4.0.dev0) (2020.12.5)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers==4.4.0.dev0) (3.0.4)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers==4.4.0.dev0) (2.10)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->transformers==4.4.0.dev0) (1.24.3)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers==4.4.0.dev0) (1.15.0)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers==4.4.0.dev0) (7.1.2)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers==4.4.0.dev0) (1.0.1)\n",
            "Requirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging->transformers==4.4.0.dev0) (2.4.7)\n",
            "Building wheels for collected packages: sacremoses\n",
            "  Building wheel for sacremoses (setup.py): started\n",
            "  Building wheel for sacremoses (setup.py): finished with status 'done'\n",
            "  Created wheel for sacremoses: filename=sacremoses-0.0.43-cp37-none-any.whl size=893262 sha256=17aa81e3eaaa3ec52e61ca295b4e16a8eeb8ab34e97b5e23cc54ebb5a35a23a1\n",
            "  Stored in directory: /root/.cache/pip/wheels/29/3c/fd/7ce5c3f0666dab31a50123635e6fb5e19ceb42ce38d4e58f45\n",
            "Successfully built sacremoses\n",
            "Installing collected packages: tokenizers, sacremoses, transformers\n",
            "  Running setup.py develop for transformers\n",
            "Successfully installed sacremoses-0.0.43 tokenizers-0.10.1 transformers\n",
            "Requirement already satisfied: tensorboard in /usr/local/lib/python3.7/dist-packages (from -r examples/_tests_requirements.txt (line 1)) (2.4.1)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.7/dist-packages (from -r examples/_tests_requirements.txt (line 2)) (0.22.2.post1)\n",
            "Collecting seqeval\n",
            "  Downloading https://files.pythonhosted.org/packages/9d/2d/233c79d5b4e5ab1dbf111242299153f3caddddbb691219f363ad55ce783d/seqeval-1.2.2.tar.gz (43kB)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.7/dist-packages (from -r examples/_tests_requirements.txt (line 4)) (5.4.8)\n",
            "Collecting sacrebleu\n",
            "  Downloading https://files.pythonhosted.org/packages/7e/57/0c7ca4e31a126189dab99c19951910bd081dea5bbd25f24b77107750eae7/sacrebleu-1.5.1-py3-none-any.whl (54kB)\n",
            "Collecting rouge-score\n",
            "  Downloading https://files.pythonhosted.org/packages/1f/56/a81022436c08b9405a5247b71635394d44fe7e1dbedc4b28c740e09c2840/rouge_score-0.0.4-py2.py3-none-any.whl\n",
            "Requirement already satisfied: tensorflow_datasets in /usr/local/lib/python3.7/dist-packages (from -r examples/_tests_requirements.txt (line 7)) (4.0.1)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.7/dist-packages (from -r examples/_tests_requirements.txt (line 8)) (3.2.2)\n",
            "Collecting git-python==1.0.3\n",
            "  Downloading https://files.pythonhosted.org/packages/8a/de/0cc6353a45cdb1e137cffac5383097b300cc578e2e1133eeb847e23a1394/git_python-1.0.3-py2.py3-none-any.whl\n",
            "Collecting faiss-cpu\n",
            "  Downloading https://files.pythonhosted.org/packages/48/0c/efd43c4feac172867409f38f07949c36602355ec7196749d10f905d09228/faiss_cpu-1.7.0-cp37-cp37m-manylinux2014_x86_64.whl (8.1MB)\n",
            "Collecting streamlit\n",
            "  Downloading https://files.pythonhosted.org/packages/76/a6/2507aedaa1c80d39eccd601129d273f4091720f4b1031997bb52630ba504/streamlit-0.79.0-py2.py3-none-any.whl (7.0MB)\n",
            "Collecting elasticsearch\n",
            "  Downloading https://files.pythonhosted.org/packages/09/93/461a042becf2a35a666fb7dbb2fa31f0f766dfd1b01e7d971f4ad51f0d69/elasticsearch-7.12.0-py2.py3-none-any.whl (334kB)\n",
            "Requirement already satisfied: nltk in /usr/local/lib/python3.7/dist-packages (from -r examples/_tests_requirements.txt (line 13)) (3.2.5)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.7/dist-packages (from -r examples/_tests_requirements.txt (line 14)) (1.1.5)\n",
            "Collecting datasets>=1.1.3\n",
            "  Downloading https://files.pythonhosted.org/packages/54/90/43b396481a8298c6010afb93b3c1e71d4ba6f8c10797a7da8eb005e45081/datasets-1.5.0-py3-none-any.whl (192kB)\n",
            "Collecting fire\n",
            "  Downloading https://files.pythonhosted.org/packages/11/07/a119a1aa04d37bc819940d95ed7e135a7dcca1c098123a3764a6dcace9e7/fire-0.4.0.tar.gz (87kB)\n",
            "Requirement already satisfied: pytest in /usr/local/lib/python3.7/dist-packages (from -r examples/_tests_requirements.txt (line 17)) (3.6.4)\n",
            "Collecting conllu\n",
            "  Downloading https://files.pythonhosted.org/packages/ae/be/be6959c3ff2dbfdd87de4be0ccdff577835b5d08b1d25bf7fd4aaf0d7add/conllu-4.4-py2.py3-none-any.whl\n",
            "Collecting sentencepiece!=0.1.92\n",
            "  Downloading https://files.pythonhosted.org/packages/f5/99/e0808cb947ba10f575839c43e8fafc9cc44e4a7a2c8f79c60db48220a577/sentencepiece-0.1.95-cp37-cp37m-manylinux2014_x86_64.whl (1.2MB)\n",
            "Requirement already satisfied: protobuf in /usr/local/lib/python3.7/dist-packages (from -r examples/_tests_requirements.txt (line 20)) (3.12.4)\n",
            "Requirement already satisfied: six>=1.10.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard->-r examples/_tests_requirements.txt (line 1)) (1.15.0)\n",
            "Requirement already satisfied: wheel>=0.26; python_version >= \"3\" in /usr/local/lib/python3.7/dist-packages (from tensorboard->-r examples/_tests_requirements.txt (line 1)) (0.36.2)\n",
            "Requirement already satisfied: grpcio>=1.24.3 in /usr/local/lib/python3.7/dist-packages (from tensorboard->-r examples/_tests_requirements.txt (line 1)) (1.32.0)\n",
            "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.7/dist-packages (from tensorboard->-r examples/_tests_requirements.txt (line 1)) (0.4.3)\n",
            "Requirement already satisfied: numpy>=1.12.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard->-r examples/_tests_requirements.txt (line 1)) (1.19.5)\n",
            "Requirement already satisfied: absl-py>=0.4 in /usr/local/lib/python3.7/dist-packages (from tensorboard->-r examples/_tests_requirements.txt (line 1)) (0.10.0)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.7/dist-packages (from tensorboard->-r examples/_tests_requirements.txt (line 1)) (3.3.4)\n",
            "Requirement already satisfied: setuptools>=41.0.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard->-r examples/_tests_requirements.txt (line 1)) (54.1.2)\n",
            "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard->-r examples/_tests_requirements.txt (line 1)) (1.8.0)\n",
            "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.7/dist-packages (from tensorboard->-r examples/_tests_requirements.txt (line 1)) (1.0.1)\n",
            "Requirement already satisfied: google-auth<2,>=1.6.3 in /usr/local/lib/python3.7/dist-packages (from tensorboard->-r examples/_tests_requirements.txt (line 1)) (1.27.1)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard->-r examples/_tests_requirements.txt (line 1)) (2.23.0)\n",
            "Requirement already satisfied: scipy>=0.17.0 in /usr/local/lib/python3.7/dist-packages (from scikit-learn->-r examples/_tests_requirements.txt (line 2)) (1.4.1)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.7/dist-packages (from scikit-learn->-r examples/_tests_requirements.txt (line 2)) (1.0.1)\n",
            "Collecting portalocker==2.0.0\n",
            "  Downloading https://files.pythonhosted.org/packages/89/a6/3814b7107e0788040870e8825eebf214d72166adf656ba7d4bf14759a06a/portalocker-2.0.0-py2.py3-none-any.whl\n",
            "Requirement already satisfied: importlib-resources; python_version < \"3.9\" in /usr/local/lib/python3.7/dist-packages (from tensorflow_datasets->-r examples/_tests_requirements.txt (line 7)) (5.1.2)\n",
            "Requirement already satisfied: future in /usr/local/lib/python3.7/dist-packages (from tensorflow_datasets->-r examples/_tests_requirements.txt (line 7)) (0.16.0)\n",
            "Requirement already satisfied: dm-tree in /usr/local/lib/python3.7/dist-packages (from tensorflow_datasets->-r examples/_tests_requirements.txt (line 7)) (0.1.5)\n",
            "Requirement already satisfied: promise in /usr/local/lib/python3.7/dist-packages (from tensorflow_datasets->-r examples/_tests_requirements.txt (line 7)) (2.3)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from tensorflow_datasets->-r examples/_tests_requirements.txt (line 7)) (4.41.1)\n",
            "Requirement already satisfied: tensorflow-metadata in /usr/local/lib/python3.7/dist-packages (from tensorflow_datasets->-r examples/_tests_requirements.txt (line 7)) (0.28.0)\n",
            "Requirement already satisfied: termcolor in /usr/local/lib/python3.7/dist-packages (from tensorflow_datasets->-r examples/_tests_requirements.txt (line 7)) (1.1.0)\n",
            "Requirement already satisfied: attrs>=18.1.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow_datasets->-r examples/_tests_requirements.txt (line 7)) (20.3.0)\n",
            "Requirement already satisfied: dill in /usr/local/lib/python3.7/dist-packages (from tensorflow_datasets->-r examples/_tests_requirements.txt (line 7)) (0.3.3)\n",
            "Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->-r examples/_tests_requirements.txt (line 8)) (2.8.1)\n",
            "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->-r examples/_tests_requirements.txt (line 8)) (2.4.7)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.7/dist-packages (from matplotlib->-r examples/_tests_requirements.txt (line 8)) (0.10.0)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->-r examples/_tests_requirements.txt (line 8)) (1.3.1)\n",
            "Collecting gitpython\n",
            "  Downloading https://files.pythonhosted.org/packages/a6/99/98019716955ba243657daedd1de8f3a88ca1f5b75057c38e959db22fb87b/GitPython-3.1.14-py3-none-any.whl (159kB)\n",
            "Collecting pydeck>=0.1.dev5\n",
            "  Downloading https://files.pythonhosted.org/packages/1c/3f/8f04ae0c22d82ec7bec7fcc03270a142f637e362bbd285f7daeeda24fbef/pydeck-0.6.1-py2.py3-none-any.whl (4.6MB)\n",
            "Requirement already satisfied: pyarrow; python_version < \"3.9\" in /usr/local/lib/python3.7/dist-packages (from streamlit->-r examples/_tests_requirements.txt (line 11)) (3.0.0)\n",
            "Requirement already satisfied: toml in /usr/local/lib/python3.7/dist-packages (from streamlit->-r examples/_tests_requirements.txt (line 11)) (0.10.2)\n",
            "Collecting watchdog; platform_system != \"Darwin\"\n",
            "  Downloading https://files.pythonhosted.org/packages/c6/ba/a36ca5b4e75649a002f06531862467b3eb5c768caa23d6d88b921fe238d8/watchdog-2.0.2-py3-none-manylinux2014_x86_64.whl (74kB)\n",
            "Requirement already satisfied: altair>=3.2.0 in /usr/local/lib/python3.7/dist-packages (from streamlit->-r examples/_tests_requirements.txt (line 11)) (4.1.0)\n",
            "Requirement already satisfied: astor in /usr/local/lib/python3.7/dist-packages (from streamlit->-r examples/_tests_requirements.txt (line 11)) (0.8.1)\n",
            "Collecting blinker\n",
            "  Downloading https://files.pythonhosted.org/packages/1b/51/e2a9f3b757eb802f61dc1f2b09c8c99f6eb01cf06416c0671253536517b6/blinker-1.4.tar.gz (111kB)\n",
            "Requirement already satisfied: cachetools>=4.0 in /usr/local/lib/python3.7/dist-packages (from streamlit->-r examples/_tests_requirements.txt (line 11)) (4.2.1)\n",
            "Requirement already satisfied: tornado>=5.0 in /usr/local/lib/python3.7/dist-packages (from streamlit->-r examples/_tests_requirements.txt (line 11)) (5.1.1)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from streamlit->-r examples/_tests_requirements.txt (line 11)) (20.9)\n",
            "Requirement already satisfied: tzlocal in /usr/local/lib/python3.7/dist-packages (from streamlit->-r examples/_tests_requirements.txt (line 11)) (1.5.1)\n",
            "Collecting validators\n",
            "  Downloading https://files.pythonhosted.org/packages/db/2f/7fed3ee94ad665ad2c1de87f858f10a7785251ff75b4fd47987888d07ef1/validators-0.18.2-py3-none-any.whl\n",
            "Collecting base58\n",
            "  Downloading https://files.pythonhosted.org/packages/b8/a1/d9f565e9910c09fd325dc638765e8843a19fa696275c16cc08cf3b0a3c25/base58-2.1.0-py3-none-any.whl\n",
            "Requirement already satisfied: click>=7.0 in /usr/local/lib/python3.7/dist-packages (from streamlit->-r examples/_tests_requirements.txt (line 11)) (7.1.2)\n",
            "Requirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.7/dist-packages (from streamlit->-r examples/_tests_requirements.txt (line 11)) (7.0.0)\n",
            "Requirement already satisfied: urllib3<2,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from elasticsearch->-r examples/_tests_requirements.txt (line 12)) (1.24.3)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.7/dist-packages (from elasticsearch->-r examples/_tests_requirements.txt (line 12)) (2020.12.5)\n",
            "Requirement already satisfied: pytz>=2017.2 in /usr/local/lib/python3.7/dist-packages (from pandas->-r examples/_tests_requirements.txt (line 14)) (2018.9)\n",
            "Requirement already satisfied: importlib-metadata; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from datasets>=1.1.3->-r examples/_tests_requirements.txt (line 15)) (3.7.2)\n",
            "Requirement already satisfied: multiprocess in /usr/local/lib/python3.7/dist-packages (from datasets>=1.1.3->-r examples/_tests_requirements.txt (line 15)) (0.70.11.1)\n",
            "Collecting huggingface-hub<0.1.0\n",
            "  Downloading https://files.pythonhosted.org/packages/af/07/bf95f398e6598202d878332280f36e589512174882536eb20d792532a57d/huggingface_hub-0.0.7-py3-none-any.whl\n",
            "Collecting xxhash\n",
            "  Downloading https://files.pythonhosted.org/packages/e7/27/1c0b37c53a7852f1c190ba5039404d27b3ae96a55f48203a74259f8213c9/xxhash-2.0.0-cp37-cp37m-manylinux2010_x86_64.whl (243kB)\n",
            "Collecting fsspec\n",
            "  Downloading https://files.pythonhosted.org/packages/91/0d/a6bfee0ddf47b254286b9bd574e6f50978c69897647ae15b14230711806e/fsspec-0.8.7-py3-none-any.whl (103kB)\n",
            "Requirement already satisfied: more-itertools>=4.0.0 in /usr/local/lib/python3.7/dist-packages (from pytest->-r examples/_tests_requirements.txt (line 17)) (8.7.0)\n",
            "Requirement already satisfied: py>=1.5.0 in /usr/local/lib/python3.7/dist-packages (from pytest->-r examples/_tests_requirements.txt (line 17)) (1.10.0)\n",
            "Requirement already satisfied: pluggy<0.8,>=0.5 in /usr/local/lib/python3.7/dist-packages (from pytest->-r examples/_tests_requirements.txt (line 17)) (0.7.1)\n",
            "Requirement already satisfied: atomicwrites>=1.0 in /usr/local/lib/python3.7/dist-packages (from pytest->-r examples/_tests_requirements.txt (line 17)) (1.4.0)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.7/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard->-r examples/_tests_requirements.txt (line 1)) (1.3.0)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4; python_version >= \"3.6\" in /usr/local/lib/python3.7/dist-packages (from google-auth<2,>=1.6.3->tensorboard->-r examples/_tests_requirements.txt (line 1)) (4.7.2)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.7/dist-packages (from google-auth<2,>=1.6.3->tensorboard->-r examples/_tests_requirements.txt (line 1)) (0.2.8)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard->-r examples/_tests_requirements.txt (line 1)) (2.10)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard->-r examples/_tests_requirements.txt (line 1)) (3.0.4)\n",
            "Requirement already satisfied: zipp>=0.4; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from importlib-resources; python_version < \"3.9\"->tensorflow_datasets->-r examples/_tests_requirements.txt (line 7)) (3.4.1)\n",
            "Requirement already satisfied: googleapis-common-protos<2,>=1.52.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow-metadata->tensorflow_datasets->-r examples/_tests_requirements.txt (line 7)) (1.53.0)\n",
            "Collecting gitdb<5,>=4.0.1\n",
            "  Downloading https://files.pythonhosted.org/packages/48/11/d1800bca0a3bae820b84b7d813ad1eff15a48a64caea9c823fc8c1b119e8/gitdb-4.0.5-py3-none-any.whl (63kB)\n",
            "Requirement already satisfied: jinja2>=2.10.1 in /usr/local/lib/python3.7/dist-packages (from pydeck>=0.1.dev5->streamlit->-r examples/_tests_requirements.txt (line 11)) (2.11.3)\n",
            "Requirement already satisfied: ipywidgets>=7.0.0 in /usr/local/lib/python3.7/dist-packages (from pydeck>=0.1.dev5->streamlit->-r examples/_tests_requirements.txt (line 11)) (7.6.3)\n",
            "Collecting ipykernel>=5.1.2; python_version >= \"3.4\"\n",
            "  Downloading https://files.pythonhosted.org/packages/56/95/3a670c8b2c2370bd8631c313f42e60983b3113ffec4035940592252bd6d5/ipykernel-5.5.0-py3-none-any.whl (120kB)\n",
            "Requirement already satisfied: traitlets>=4.3.2 in /usr/local/lib/python3.7/dist-packages (from pydeck>=0.1.dev5->streamlit->-r examples/_tests_requirements.txt (line 11)) (5.0.5)\n",
            "Requirement already satisfied: toolz in /usr/local/lib/python3.7/dist-packages (from altair>=3.2.0->streamlit->-r examples/_tests_requirements.txt (line 11)) (0.11.1)\n",
            "Requirement already satisfied: entrypoints in /usr/local/lib/python3.7/dist-packages (from altair>=3.2.0->streamlit->-r examples/_tests_requirements.txt (line 11)) (0.3)\n",
            "Requirement already satisfied: jsonschema in /usr/local/lib/python3.7/dist-packages (from altair>=3.2.0->streamlit->-r examples/_tests_requirements.txt (line 11)) (2.6.0)\n",
            "Requirement already satisfied: decorator>=3.4.0 in /usr/local/lib/python3.7/dist-packages (from validators->streamlit->-r examples/_tests_requirements.txt (line 11)) (4.4.2)\n",
            "Requirement already satisfied: typing-extensions>=3.6.4; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from importlib-metadata; python_version < \"3.8\"->datasets>=1.1.3->-r examples/_tests_requirements.txt (line 15)) (3.7.4.3)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from huggingface-hub<0.1.0->datasets>=1.1.3->-r examples/_tests_requirements.txt (line 15)) (3.0.12)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.7/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard->-r examples/_tests_requirements.txt (line 1)) (3.1.0)\n",
            "Requirement already satisfied: pyasn1>=0.1.3 in /usr/local/lib/python3.7/dist-packages (from rsa<5,>=3.1.4; python_version >= \"3.6\"->google-auth<2,>=1.6.3->tensorboard->-r examples/_tests_requirements.txt (line 1)) (0.4.8)\n",
            "Collecting smmap<4,>=3.0.1\n",
            "  Downloading https://files.pythonhosted.org/packages/d5/1e/6130925131f639b2acde0f7f18b73e33ce082ff2d90783c436b52040af5a/smmap-3.0.5-py2.py3-none-any.whl\n",
            "Requirement already satisfied: MarkupSafe>=0.23 in /usr/local/lib/python3.7/dist-packages (from jinja2>=2.10.1->pydeck>=0.1.dev5->streamlit->-r examples/_tests_requirements.txt (line 11)) (1.1.1)\n",
            "Requirement already satisfied: widgetsnbextension~=3.5.0 in /usr/local/lib/python3.7/dist-packages (from ipywidgets>=7.0.0->pydeck>=0.1.dev5->streamlit->-r examples/_tests_requirements.txt (line 11)) (3.5.1)\n",
            "Requirement already satisfied: nbformat>=4.2.0 in /usr/local/lib/python3.7/dist-packages (from ipywidgets>=7.0.0->pydeck>=0.1.dev5->streamlit->-r examples/_tests_requirements.txt (line 11)) (5.1.2)\n",
            "Requirement already satisfied: jupyterlab-widgets>=1.0.0; python_version >= \"3.6\" in /usr/local/lib/python3.7/dist-packages (from ipywidgets>=7.0.0->pydeck>=0.1.dev5->streamlit->-r examples/_tests_requirements.txt (line 11)) (1.0.0)\n",
            "Requirement already satisfied: ipython>=4.0.0; python_version >= \"3.3\" in /usr/local/lib/python3.7/dist-packages (from ipywidgets>=7.0.0->pydeck>=0.1.dev5->streamlit->-r examples/_tests_requirements.txt (line 11)) (5.5.0)\n",
            "Requirement already satisfied: jupyter-client in /usr/local/lib/python3.7/dist-packages (from ipykernel>=5.1.2; python_version >= \"3.4\"->pydeck>=0.1.dev5->streamlit->-r examples/_tests_requirements.txt (line 11)) (5.3.5)\n",
            "Requirement already satisfied: ipython-genutils in /usr/local/lib/python3.7/dist-packages (from traitlets>=4.3.2->pydeck>=0.1.dev5->streamlit->-r examples/_tests_requirements.txt (line 11)) (0.2.0)\n",
            "Requirement already satisfied: notebook>=4.4.1 in /usr/local/lib/python3.7/dist-packages (from widgetsnbextension~=3.5.0->ipywidgets>=7.0.0->pydeck>=0.1.dev5->streamlit->-r examples/_tests_requirements.txt (line 11)) (5.3.1)\n",
            "Requirement already satisfied: jupyter-core in /usr/local/lib/python3.7/dist-packages (from nbformat>=4.2.0->ipywidgets>=7.0.0->pydeck>=0.1.dev5->streamlit->-r examples/_tests_requirements.txt (line 11)) (4.7.1)\n",
            "Requirement already satisfied: pickleshare in /usr/local/lib/python3.7/dist-packages (from ipython>=4.0.0; python_version >= \"3.3\"->ipywidgets>=7.0.0->pydeck>=0.1.dev5->streamlit->-r examples/_tests_requirements.txt (line 11)) (0.7.5)\n",
            "Requirement already satisfied: simplegeneric>0.8 in /usr/local/lib/python3.7/dist-packages (from ipython>=4.0.0; python_version >= \"3.3\"->ipywidgets>=7.0.0->pydeck>=0.1.dev5->streamlit->-r examples/_tests_requirements.txt (line 11)) (0.8.1)\n",
            "Requirement already satisfied: prompt-toolkit<2.0.0,>=1.0.4 in /usr/local/lib/python3.7/dist-packages (from ipython>=4.0.0; python_version >= \"3.3\"->ipywidgets>=7.0.0->pydeck>=0.1.dev5->streamlit->-r examples/_tests_requirements.txt (line 11)) (1.0.18)\n",
            "Requirement already satisfied: pygments in /usr/local/lib/python3.7/dist-packages (from ipython>=4.0.0; python_version >= \"3.3\"->ipywidgets>=7.0.0->pydeck>=0.1.dev5->streamlit->-r examples/_tests_requirements.txt (line 11)) (2.6.1)\n",
            "Requirement already satisfied: pexpect; sys_platform != \"win32\" in /usr/local/lib/python3.7/dist-packages (from ipython>=4.0.0; python_version >= \"3.3\"->ipywidgets>=7.0.0->pydeck>=0.1.dev5->streamlit->-r examples/_tests_requirements.txt (line 11)) (4.8.0)\n",
            "Requirement already satisfied: pyzmq>=13 in /usr/local/lib/python3.7/dist-packages (from jupyter-client->ipykernel>=5.1.2; python_version >= \"3.4\"->pydeck>=0.1.dev5->streamlit->-r examples/_tests_requirements.txt (line 11)) (22.0.3)\n",
            "Requirement already satisfied: Send2Trash in /usr/local/lib/python3.7/dist-packages (from notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets>=7.0.0->pydeck>=0.1.dev5->streamlit->-r examples/_tests_requirements.txt (line 11)) (1.5.0)\n",
            "Requirement already satisfied: terminado>=0.8.1 in /usr/local/lib/python3.7/dist-packages (from notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets>=7.0.0->pydeck>=0.1.dev5->streamlit->-r examples/_tests_requirements.txt (line 11)) (0.9.2)\n",
            "Requirement already satisfied: nbconvert in /usr/local/lib/python3.7/dist-packages (from notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets>=7.0.0->pydeck>=0.1.dev5->streamlit->-r examples/_tests_requirements.txt (line 11)) (5.6.1)\n",
            "Requirement already satisfied: wcwidth in /usr/local/lib/python3.7/dist-packages (from prompt-toolkit<2.0.0,>=1.0.4->ipython>=4.0.0; python_version >= \"3.3\"->ipywidgets>=7.0.0->pydeck>=0.1.dev5->streamlit->-r examples/_tests_requirements.txt (line 11)) (0.2.5)\n",
            "Requirement already satisfied: ptyprocess>=0.5 in /usr/local/lib/python3.7/dist-packages (from pexpect; sys_platform != \"win32\"->ipython>=4.0.0; python_version >= \"3.3\"->ipywidgets>=7.0.0->pydeck>=0.1.dev5->streamlit->-r examples/_tests_requirements.txt (line 11)) (0.7.0)\n",
            "Requirement already satisfied: mistune<2,>=0.8.1 in /usr/local/lib/python3.7/dist-packages (from nbconvert->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets>=7.0.0->pydeck>=0.1.dev5->streamlit->-r examples/_tests_requirements.txt (line 11)) (0.8.4)\n",
            "Requirement already satisfied: testpath in /usr/local/lib/python3.7/dist-packages (from nbconvert->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets>=7.0.0->pydeck>=0.1.dev5->streamlit->-r examples/_tests_requirements.txt (line 11)) (0.4.4)\n",
            "Requirement already satisfied: pandocfilters>=1.4.1 in /usr/local/lib/python3.7/dist-packages (from nbconvert->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets>=7.0.0->pydeck>=0.1.dev5->streamlit->-r examples/_tests_requirements.txt (line 11)) (1.4.3)\n",
            "Requirement already satisfied: defusedxml in /usr/local/lib/python3.7/dist-packages (from nbconvert->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets>=7.0.0->pydeck>=0.1.dev5->streamlit->-r examples/_tests_requirements.txt (line 11)) (0.7.1)\n",
            "Requirement already satisfied: bleach in /usr/local/lib/python3.7/dist-packages (from nbconvert->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets>=7.0.0->pydeck>=0.1.dev5->streamlit->-r examples/_tests_requirements.txt (line 11)) (3.3.0)\n",
            "Requirement already satisfied: webencodings in /usr/local/lib/python3.7/dist-packages (from bleach->nbconvert->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets>=7.0.0->pydeck>=0.1.dev5->streamlit->-r examples/_tests_requirements.txt (line 11)) (0.5.1)\n",
            "Building wheels for collected packages: seqeval, fire, blinker\n",
            "  Building wheel for seqeval (setup.py): started\n",
            "  Building wheel for seqeval (setup.py): finished with status 'done'\n",
            "  Created wheel for seqeval: filename=seqeval-1.2.2-cp37-none-any.whl size=16172 sha256=9bd2ea2cd7bc25abdfa7d210d98ebfa899cbbb77ff600a78241f6644ebdad368\n",
            "  Stored in directory: /root/.cache/pip/wheels/52/df/1b/45d75646c37428f7e626214704a0e35bd3cfc32eda37e59e5f\n",
            "  Building wheel for fire (setup.py): started\n",
            "  Building wheel for fire (setup.py): finished with status 'done'\n",
            "  Created wheel for fire: filename=fire-0.4.0-py2.py3-none-any.whl size=115928 sha256=d168a509b588a36c3b8b35b4b1b4fd08585f3b0194364f44b5ee4b93bd7bd4f5\n",
            "  Stored in directory: /root/.cache/pip/wheels/af/19/30/1ea0cad502dcb4e66ed5a690279628c827aea38bbbab75d5ed\n",
            "  Building wheel for blinker (setup.py): started\n",
            "  Building wheel for blinker (setup.py): finished with status 'done'\n",
            "  Created wheel for blinker: filename=blinker-1.4-cp37-none-any.whl size=13448 sha256=349334c10dc09daeda682f275f14c3238719de76b93c92a776b00b8e2a0f5320\n",
            "  Stored in directory: /root/.cache/pip/wheels/92/a0/00/8690a57883956a301d91cf4ec999cc0b258b01e3f548f86e89\n",
            "Successfully built seqeval fire blinker\n",
            "Installing collected packages: seqeval, portalocker, sacrebleu, rouge-score, smmap, gitdb, gitpython, git-python, faiss-cpu, ipykernel, pydeck, watchdog, blinker, validators, base58, streamlit, elasticsearch, huggingface-hub, xxhash, fsspec, datasets, fire, conllu, sentencepiece\n",
            "  Found existing installation: ipykernel 4.10.1\n",
            "    Uninstalling ipykernel-4.10.1:\n",
            "      Successfully uninstalled ipykernel-4.10.1\n",
            "Successfully installed base58-2.1.0 blinker-1.4 conllu-4.4 datasets-1.5.0 elasticsearch-7.12.0 faiss-cpu-1.7.0 fire-0.4.0 fsspec-0.8.7 git-python-1.0.3 gitdb-4.0.5 gitpython-3.1.14 huggingface-hub-0.0.7 ipykernel-5.5.0 portalocker-2.0.0 pydeck-0.6.1 rouge-score-0.0.4 sacrebleu-1.5.1 sentencepiece-0.1.95 seqeval-1.2.2 smmap-3.0.5 streamlit-0.79.0 validators-0.18.2 watchdog-2.0.2 xxhash-2.0.0\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Cloning into 'transformers'...\n",
            "Note: checking out '1aa9c13f70ae75be7fd6'.\n",
            "\n",
            "You are in 'detached HEAD' state. You can look around, make experimental\n",
            "changes and commit them, and you can discard any commits you make in this\n",
            "state without impacting any branches by performing another checkout.\n",
            "\n",
            "If you want to create a new branch to retain commits you create, you may\n",
            "do so (now or later) by using -b with the checkout command again. Example:\n",
            "\n",
            "  git checkout -b <new-branch-name>\n",
            "\n",
            "HEAD is now at 1aa9c13f7 Fix GPU tests with speech\n",
            "ERROR: google-colab 1.0.0 has requirement ipykernel~=4.10, but you'll have ipykernel 5.5.0 which is incompatible.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E2sXN7bS9_ou"
      },
      "source": [
        "%%bash\n",
        "\n",
        "cd transformers\n",
        "\n",
        "cat <<'EOT' > ds_config.json\n",
        "{\n",
        "    \"fp16\": {\n",
        "        \"enabled\": true,\n",
        "        \"loss_scale\": 0,\n",
        "        \"loss_scale_window\": 1000,\n",
        "        \"initial_scale_power\": 16,        \n",
        "        \"hysteresis\": 2,\n",
        "        \"min_loss_scale\": 1\n",
        "    },\n",
        "\n",
        "    \"zero_optimization\": {\n",
        "        \"stage\": 2,\n",
        "       \"allgather_partitions\": true,\n",
        "       \"allgather_bucket_size\": 2e8,\n",
        "       \"reduce_scatter\": true,\n",
        "       \"reduce_bucket_size\": 2e8,\n",
        "        \"overlap_comm\": true,\n",
        "        \"contiguous_gradients\": true,\n",
        "        \"cpu_offload\": false\n",
        "    },\n",
        "\n",
        "    \"optimizer\": {\n",
        "        \"type\": \"AdamW\",\n",
        "        \"params\": {\n",
        "            \"lr\": 3e-5,\n",
        "            \"betas\": [ 0.9, 0.999 ],\n",
        "            \"eps\": 1e-8,\n",
        "            \"weight_decay\": 3e-7\n",
        "        }\n",
        "    },\n",
        "\n",
        "    \"scheduler\": {\n",
        "        \"type\": \"WarmupLR\",\n",
        "        \"params\": {\n",
        "            \"warmup_min_lr\": 0,\n",
        "            \"warmup_max_lr\": 3e-5,\n",
        "            \"warmup_num_steps\": 500\n",
        "        }\n",
        "    },\n",
        "    \"steps_per_print\": 2000,\n",
        "    \"wall_clock_breakdown\": false\n",
        "}\n",
        "EOT"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8J7NnYX5-Fuq"
      },
      "source": [
        "# !ls -l transformers\n",
        "#!cat transformers/ds_config.json"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8ibDyTZg-hDV",
        "outputId": "ebbe40af-4ac7-4f96-d87e-a0b5579751e6"
      },
      "source": [
        "!cd transformers; export BS=16; rm -r output_dir; PYTHONPATH=src USE_TF=0 CUDA_VISIBLE_DEVICES=0 deepspeed --num_gpus=1 examples/seq2seq/run_seq2seq.py --model_name_or_path google/mt5-small \\\n",
        "--output_dir output_dir --adam_eps 1e-06  --evaluation_strategy=steps  --do_train --label_smoothing 0.1 --learning_rate 3e-5 --logging_first_step --logging_steps 1000 \\\n",
        "--max_source_length 128 --max_target_length 128 --num_train_epochs 1 --overwrite_output_dir  --per_device_train_batch_size $BS --predict_with_generate --sortish_sampler \\\n",
        "--val_max_target_length 128 --warmup_steps 500 --max_train_samples 2000 --max_val_samples 500 \\\n",
        "--task translation_en_to_ro  --dataset_name wmt16 --dataset_config ro-en --source_prefix \"translate English to Romanian: \" --deepspeed  ds_config.json --fp16"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "rm: cannot remove 'output_dir': No such file or directory\n",
            "[2021-03-25 02:35:35,855] [WARNING] [runner.py:117:fetch_hostfile] Unable to find hostfile, will proceed with training with local resources only.\n",
            "[2021-03-25 02:35:35,873] [INFO] [runner.py:358:main] cmd = /usr/bin/python3 -u -m deepspeed.launcher.launch --world_info=eyJsb2NhbGhvc3QiOiBbMF19 --master_addr=127.0.0.1 --master_port=29500 examples/seq2seq/run_seq2seq.py --model_name_or_path google/mt5-small --output_dir output_dir --adam_eps 1e-06 --evaluation_strategy=steps --do_train --label_smoothing 0.1 --learning_rate 3e-5 --logging_first_step --logging_steps 1000 --max_source_length 128 --max_target_length 128 --num_train_epochs 1 --overwrite_output_dir --per_device_train_batch_size 16 --predict_with_generate --sortish_sampler --val_max_target_length 128 --warmup_steps 500 --max_train_samples 2000 --max_val_samples 500 --task translation_en_to_ro --dataset_name wmt16 --dataset_config ro-en --source_prefix translate English to Romanian:  --deepspeed ds_config.json --fp16\n",
            "[2021-03-25 02:35:36,888] [INFO] [launch.py:73:main] 0 NCCL_VERSION 2.7.8\n",
            "[2021-03-25 02:35:36,888] [INFO] [launch.py:80:main] WORLD INFO DICT: {'localhost': [0]}\n",
            "[2021-03-25 02:35:36,888] [INFO] [launch.py:89:main] nnodes=1, num_local_procs=1, node_rank=0\n",
            "[2021-03-25 02:35:36,888] [INFO] [launch.py:101:main] global_rank_mapping=defaultdict(<class 'list'>, {'localhost': [0]})\n",
            "[2021-03-25 02:35:36,888] [INFO] [launch.py:102:main] dist_world_size=1\n",
            "[2021-03-25 02:35:36,888] [INFO] [launch.py:105:main] Setting CUDA_VISIBLE_DEVICES=0\n",
            "[2021-03-25 02:35:41,722] [INFO] [distributed.py:47:init_distributed] Initializing torch distributed with backend: nccl\n",
            "03/25/2021 02:35:44 - WARNING - __main__ -   Process rank: 0, device: cuda:0, n_gpu: 1distributed training: True, 16-bits training: True\n",
            "03/25/2021 02:35:44 - INFO - __main__ -   Training/evaluation parameters Seq2SeqTrainingArguments(output_dir='output_dir', overwrite_output_dir=True, do_train=True, do_eval=None, do_predict=False, evaluation_strategy=<IntervalStrategy.STEPS: 'steps'>, prediction_loss_only=False, per_device_train_batch_size=16, per_device_eval_batch_size=8, per_gpu_train_batch_size=None, per_gpu_eval_batch_size=None, gradient_accumulation_steps=1, eval_accumulation_steps=None, learning_rate=3e-05, weight_decay=0.0, adam_beta1=0.9, adam_beta2=0.999, adam_epsilon=1e-06, max_grad_norm=1.0, num_train_epochs=1.0, max_steps=-1, lr_scheduler_type=<SchedulerType.LINEAR: 'linear'>, warmup_ratio=0.0, warmup_steps=500, logging_dir='runs/Mar25_02-35-41_f2c2b5c6b880', logging_strategy=<IntervalStrategy.STEPS: 'steps'>, logging_first_step=True, logging_steps=1000, save_strategy=<IntervalStrategy.STEPS: 'steps'>, save_steps=500, save_total_limit=None, no_cuda=False, seed=42, fp16=True, fp16_opt_level='O1', fp16_backend='auto', fp16_full_eval=False, local_rank=0, tpu_num_cores=None, tpu_metrics_debug=False, debug=False, dataloader_drop_last=False, eval_steps=1000, dataloader_num_workers=0, past_index=-1, run_name='output_dir', disable_tqdm=False, remove_unused_columns=True, label_names=None, load_best_model_at_end=False, metric_for_best_model=None, greater_is_better=None, ignore_data_skip=False, sharded_ddp=[], deepspeed='ds_config.json', label_smoothing_factor=0.1, adafactor=False, group_by_length=False, report_to=['tensorboard'], ddp_find_unused_parameters=None, dataloader_pin_memory=True, skip_memory_metrics=False, sortish_sampler=True, predict_with_generate=True)\n",
            "Downloading: 2.81kB [00:00, 2.62MB/s]       \n",
            "Downloading: 3.19kB [00:00, 3.72MB/s]       \n",
            "Downloading: 41.1kB [00:00, 34.7MB/s]       \n",
            "Downloading and preparing dataset wmt16/ro-en (download: Unknown size, generated: Unknown size, post-processed: Unknown size, total: Unknown size) to /root/.cache/huggingface/datasets/wmt16/ro-en/1.0.0/9dc00622c30446e99c4c63d12a484ea4fb653f2f37c867d6edcec839d7eae50f...\n",
            "Downloading: 100% 225M/225M [00:04<00:00, 53.1MB/s]\n",
            "Downloading: 100% 23.5M/23.5M [00:02<00:00, 8.48MB/s]\n",
            "Downloading: 100% 38.7M/38.7M [00:00<00:00, 53.2MB/s]\n",
            "Dataset wmt16 downloaded and prepared to /root/.cache/huggingface/datasets/wmt16/ro-en/1.0.0/9dc00622c30446e99c4c63d12a484ea4fb653f2f37c867d6edcec839d7eae50f. Subsequent calls will reuse this data.\n",
            "https://huggingface.co/google/mt5-small/resolve/main/config.json not found in cache or force_download set to True, downloading to /root/.cache/huggingface/transformers/tmpj7lh9zc8\n",
            "Downloading: 100% 553/553 [00:00<00:00, 515kB/s]\n",
            "storing https://huggingface.co/google/mt5-small/resolve/main/config.json in cache at /root/.cache/huggingface/transformers/97693496c1a0cae463bd18428187f9e9924d2dfbadaa46e4d468634a0fc95a41.dadce13f8f85f4825168354a04675d4b177749f8f11b167e87676777695d4fe4\n",
            "creating metadata file for /root/.cache/huggingface/transformers/97693496c1a0cae463bd18428187f9e9924d2dfbadaa46e4d468634a0fc95a41.dadce13f8f85f4825168354a04675d4b177749f8f11b167e87676777695d4fe4\n",
            "loading configuration file https://huggingface.co/google/mt5-small/resolve/main/config.json from cache at /root/.cache/huggingface/transformers/97693496c1a0cae463bd18428187f9e9924d2dfbadaa46e4d468634a0fc95a41.dadce13f8f85f4825168354a04675d4b177749f8f11b167e87676777695d4fe4\n",
            "Model config MT5Config {\n",
            "  \"architectures\": [\n",
            "    \"MT5ForConditionalGeneration\"\n",
            "  ],\n",
            "  \"d_ff\": 1024,\n",
            "  \"d_kv\": 64,\n",
            "  \"d_model\": 512,\n",
            "  \"decoder_start_token_id\": 0,\n",
            "  \"dropout_rate\": 0.1,\n",
            "  \"eos_token_id\": 1,\n",
            "  \"feed_forward_proj\": \"gated-gelu\",\n",
            "  \"initializer_factor\": 1.0,\n",
            "  \"is_encoder_decoder\": true,\n",
            "  \"layer_norm_epsilon\": 1e-06,\n",
            "  \"model_type\": \"mt5\",\n",
            "  \"num_decoder_layers\": 8,\n",
            "  \"num_heads\": 6,\n",
            "  \"num_layers\": 8,\n",
            "  \"pad_token_id\": 0,\n",
            "  \"relative_attention_num_buckets\": 32,\n",
            "  \"tie_word_embeddings\": false,\n",
            "  \"tokenizer_class\": \"T5Tokenizer\",\n",
            "  \"transformers_version\": \"4.4.0.dev0\",\n",
            "  \"use_cache\": true,\n",
            "  \"vocab_size\": 250112\n",
            "}\n",
            "\n",
            "loading configuration file https://huggingface.co/google/mt5-small/resolve/main/config.json from cache at /root/.cache/huggingface/transformers/97693496c1a0cae463bd18428187f9e9924d2dfbadaa46e4d468634a0fc95a41.dadce13f8f85f4825168354a04675d4b177749f8f11b167e87676777695d4fe4\n",
            "Model config MT5Config {\n",
            "  \"architectures\": [\n",
            "    \"MT5ForConditionalGeneration\"\n",
            "  ],\n",
            "  \"d_ff\": 1024,\n",
            "  \"d_kv\": 64,\n",
            "  \"d_model\": 512,\n",
            "  \"decoder_start_token_id\": 0,\n",
            "  \"dropout_rate\": 0.1,\n",
            "  \"eos_token_id\": 1,\n",
            "  \"feed_forward_proj\": \"gated-gelu\",\n",
            "  \"initializer_factor\": 1.0,\n",
            "  \"is_encoder_decoder\": true,\n",
            "  \"layer_norm_epsilon\": 1e-06,\n",
            "  \"model_type\": \"mt5\",\n",
            "  \"num_decoder_layers\": 8,\n",
            "  \"num_heads\": 6,\n",
            "  \"num_layers\": 8,\n",
            "  \"pad_token_id\": 0,\n",
            "  \"relative_attention_num_buckets\": 32,\n",
            "  \"tie_word_embeddings\": false,\n",
            "  \"tokenizer_class\": \"T5Tokenizer\",\n",
            "  \"transformers_version\": \"4.4.0.dev0\",\n",
            "  \"use_cache\": true,\n",
            "  \"vocab_size\": 250112\n",
            "}\n",
            "\n",
            "Model name 'google/mt5-small' not found in model shortcut name list (t5-small, t5-base, t5-large, t5-3b, t5-11b). Assuming 'google/mt5-small' is a path, a model identifier, or url to a directory containing tokenizer files.\n",
            "https://huggingface.co/google/mt5-small/resolve/main/spiece.model not found in cache or force_download set to True, downloading to /root/.cache/huggingface/transformers/tmp_l0vyj2q\n",
            "Downloading: 100% 4.31M/4.31M [00:00<00:00, 8.03MB/s]\n",
            "storing https://huggingface.co/google/mt5-small/resolve/main/spiece.model in cache at /root/.cache/huggingface/transformers/37d0f67f084f8c5fc5589e0bba5ff3c6307af833bb0b7f4eb33fbfd8d4038a9d.84ea7af2df68dc8db434d3160aab65cce8ac63ce5b6f7743f8c9a4a14b4f77e2\n",
            "creating metadata file for /root/.cache/huggingface/transformers/37d0f67f084f8c5fc5589e0bba5ff3c6307af833bb0b7f4eb33fbfd8d4038a9d.84ea7af2df68dc8db434d3160aab65cce8ac63ce5b6f7743f8c9a4a14b4f77e2\n",
            "https://huggingface.co/google/mt5-small/resolve/main/special_tokens_map.json not found in cache or force_download set to True, downloading to /root/.cache/huggingface/transformers/tmp204vcvcd\n",
            "Downloading: 100% 99.0/99.0 [00:00<00:00, 96.6kB/s]\n",
            "storing https://huggingface.co/google/mt5-small/resolve/main/special_tokens_map.json in cache at /root/.cache/huggingface/transformers/685ac0ca8568ec593a48b61b0a3c272beee9bc194a3c7241d15dcadb5f875e53.f76030f3ec1b96a8199b2593390c610e76ca8028ef3d24680000619ffb646276\n",
            "creating metadata file for /root/.cache/huggingface/transformers/685ac0ca8568ec593a48b61b0a3c272beee9bc194a3c7241d15dcadb5f875e53.f76030f3ec1b96a8199b2593390c610e76ca8028ef3d24680000619ffb646276\n",
            "https://huggingface.co/google/mt5-small/resolve/main/tokenizer_config.json not found in cache or force_download set to True, downloading to /root/.cache/huggingface/transformers/tmp8v605ttr\n",
            "Downloading: 100% 82.0/82.0 [00:00<00:00, 90.0kB/s]\n",
            "storing https://huggingface.co/google/mt5-small/resolve/main/tokenizer_config.json in cache at /root/.cache/huggingface/transformers/6a9e52d6dd21568e37b65fc180ada927968e8f7124f0acd6efcaf90cd2e0f4bb.4b81e5d952ad810ca1de2b3e362b9a26a5cc77b4b75daf20caf69fb838751c32\n",
            "creating metadata file for /root/.cache/huggingface/transformers/6a9e52d6dd21568e37b65fc180ada927968e8f7124f0acd6efcaf90cd2e0f4bb.4b81e5d952ad810ca1de2b3e362b9a26a5cc77b4b75daf20caf69fb838751c32\n",
            "loading file https://huggingface.co/google/mt5-small/resolve/main/spiece.model from cache at /root/.cache/huggingface/transformers/37d0f67f084f8c5fc5589e0bba5ff3c6307af833bb0b7f4eb33fbfd8d4038a9d.84ea7af2df68dc8db434d3160aab65cce8ac63ce5b6f7743f8c9a4a14b4f77e2\n",
            "loading file https://huggingface.co/google/mt5-small/resolve/main/tokenizer.json from cache at None\n",
            "loading file https://huggingface.co/google/mt5-small/resolve/main/added_tokens.json from cache at None\n",
            "loading file https://huggingface.co/google/mt5-small/resolve/main/special_tokens_map.json from cache at /root/.cache/huggingface/transformers/685ac0ca8568ec593a48b61b0a3c272beee9bc194a3c7241d15dcadb5f875e53.f76030f3ec1b96a8199b2593390c610e76ca8028ef3d24680000619ffb646276\n",
            "loading file https://huggingface.co/google/mt5-small/resolve/main/tokenizer_config.json from cache at /root/.cache/huggingface/transformers/6a9e52d6dd21568e37b65fc180ada927968e8f7124f0acd6efcaf90cd2e0f4bb.4b81e5d952ad810ca1de2b3e362b9a26a5cc77b4b75daf20caf69fb838751c32\n",
            "https://huggingface.co/google/mt5-small/resolve/main/pytorch_model.bin not found in cache or force_download set to True, downloading to /root/.cache/huggingface/transformers/tmp_9k32ivp\n",
            "Downloading: 100% 1.20G/1.20G [00:22<00:00, 54.3MB/s]\n",
            "storing https://huggingface.co/google/mt5-small/resolve/main/pytorch_model.bin in cache at /root/.cache/huggingface/transformers/8e7b2a80ddcb5611b27d8c89e1e8e33a947e105415051402a22b9c8d7d1caeb0.e22331f3a065b885b30ae3dd1ff11ccaf7fbc444485f6eb07ef5e0138bca8b70\n",
            "creating metadata file for /root/.cache/huggingface/transformers/8e7b2a80ddcb5611b27d8c89e1e8e33a947e105415051402a22b9c8d7d1caeb0.e22331f3a065b885b30ae3dd1ff11ccaf7fbc444485f6eb07ef5e0138bca8b70\n",
            "loading weights file https://huggingface.co/google/mt5-small/resolve/main/pytorch_model.bin from cache at /root/.cache/huggingface/transformers/8e7b2a80ddcb5611b27d8c89e1e8e33a947e105415051402a22b9c8d7d1caeb0.e22331f3a065b885b30ae3dd1ff11ccaf7fbc444485f6eb07ef5e0138bca8b70\n",
            "All model checkpoint weights were used when initializing MT5ForConditionalGeneration.\n",
            "\n",
            "All the weights of MT5ForConditionalGeneration were initialized from the model checkpoint at google/mt5-small.\n",
            "If your task is similar to the task the model of the checkpoint was trained on, you can already use MT5ForConditionalGeneration for predictions without further training.\n",
            "100% 2/2 [00:00<00:00, 13.83ba/s]\n",
            "Downloading: 5.40kB [00:00, 5.37MB/s]       \n",
            "Using amp fp16 backend\n",
            "Keeping the `optimizer` config from ds_config.json intact, ignoring any optimizer-specific cl args\n",
            "Keeping the `scheduler` config from ds_config.json intact, ignoring any scheduler-specific cl args\n",
            "Keeping the `fp16` config from ds_config.json intact, ignoring any fp16-specific cl args\n",
            "[2021-03-25 02:36:54,086] [INFO] [logging.py:60:log_dist] [Rank 0] DeepSpeed info: version=0.3.13, git-hash=unknown, git-branch=unknown\n",
            "[2021-03-25 02:36:54,621] [INFO] [engine.py:77:_initialize_parameter_parallel_groups] data_parallel_size: 1, parameter_parallel_size: 1\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "Using /root/.cache/torch_extensions as PyTorch extensions root...\n",
            "Creating extension directory /root/.cache/torch_extensions/fused_adam...\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "Detected CUDA files, patching ldflags\n",
            "Emitting ninja build file /root/.cache/torch_extensions/fused_adam/build.ninja...\n",
            "Building extension module fused_adam...\n",
            "Allowing ninja to set a default number of workers... (overridable by setting the environment variable MAX_JOBS=N)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "[1/3] /usr/local/cuda/bin/nvcc -DTORCH_EXTENSION_NAME=fused_adam -DTORCH_API_INCLUDE_EXTENSION_H -DPYBIND11_COMPILER_TYPE=\\\"_gcc\\\" -DPYBIND11_STDLIB=\\\"_libstdcpp\\\" -DPYBIND11_BUILD_ABI=\\\"_cxxabi1011\\\" -I/usr/local/lib/python3.7/dist-packages/deepspeed/ops/csrc/includes -isystem /usr/local/lib/python3.7/dist-packages/torch/include -isystem /usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include -isystem /usr/local/lib/python3.7/dist-packages/torch/include/TH -isystem /usr/local/lib/python3.7/dist-packages/torch/include/THC -isystem /usr/local/cuda/include -isystem /usr/include/python3.7m -D_GLIBCXX_USE_CXX11_ABI=0 -D__CUDA_NO_HALF_OPERATORS__ -D__CUDA_NO_HALF_CONVERSIONS__ -D__CUDA_NO_HALF2_OPERATORS__ --expt-relaxed-constexpr -gencode=arch=compute_60,code=sm_60 --compiler-options '-fPIC' -lineinfo -O3 --use_fast_math -DVERSION_GE_1_1 -DVERSION_GE_1_3 -DVERSION_GE_1_5 -gencode=arch=compute_60,code=sm_60 -gencode=arch=compute_60,code=compute_60 -std=c++14 -c /usr/local/lib/python3.7/dist-packages/deepspeed/ops/csrc/adam/multi_tensor_adam.cu -o multi_tensor_adam.cuda.o \n",
            "[2/3] c++ -MMD -MF fused_adam_frontend.o.d -DTORCH_EXTENSION_NAME=fused_adam -DTORCH_API_INCLUDE_EXTENSION_H -DPYBIND11_COMPILER_TYPE=\\\"_gcc\\\" -DPYBIND11_STDLIB=\\\"_libstdcpp\\\" -DPYBIND11_BUILD_ABI=\\\"_cxxabi1011\\\" -I/usr/local/lib/python3.7/dist-packages/deepspeed/ops/csrc/includes -isystem /usr/local/lib/python3.7/dist-packages/torch/include -isystem /usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include -isystem /usr/local/lib/python3.7/dist-packages/torch/include/TH -isystem /usr/local/lib/python3.7/dist-packages/torch/include/THC -isystem /usr/local/cuda/include -isystem /usr/include/python3.7m -D_GLIBCXX_USE_CXX11_ABI=0 -fPIC -std=c++14 -O3 -DVERSION_GE_1_1 -DVERSION_GE_1_3 -DVERSION_GE_1_5 -c /usr/local/lib/python3.7/dist-packages/deepspeed/ops/csrc/adam/fused_adam_frontend.cpp -o fused_adam_frontend.o \n",
            "[3/3] c++ fused_adam_frontend.o multi_tensor_adam.cuda.o -shared -L/usr/local/lib/python3.7/dist-packages/torch/lib -lc10 -lc10_cuda -ltorch_cpu -ltorch_cuda -ltorch -ltorch_python -L/usr/local/cuda/lib64 -lcudart -o fused_adam.so\n",
            "Loading extension module fused_adam...\n",
            "Time to load fused_adam op: 22.764939069747925 seconds\n",
            "[2021-03-25 02:37:18,690] [INFO] [engine.py:602:_configure_optimizer] Using DeepSpeed Optimizer param name adamw as basic optimizer\n",
            "[2021-03-25 02:37:18,690] [INFO] [engine.py:606:_configure_optimizer] DeepSpeed Basic Optimizer = FusedAdam\n",
            "Checking ZeRO support for optimizer=FusedAdam type=<class 'deepspeed.ops.adam.fused_adam.FusedAdam'>\n",
            "[2021-03-25 02:37:18,690] [INFO] [logging.py:60:log_dist] [Rank 0] Creating fp16 ZeRO stage 2 optimizer\n",
            "Using /root/.cache/torch_extensions as PyTorch extensions root...\n",
            "Creating extension directory /root/.cache/torch_extensions/utils...\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "Emitting ninja build file /root/.cache/torch_extensions/utils/build.ninja...\n",
            "Building extension module utils...\n",
            "Allowing ninja to set a default number of workers... (overridable by setting the environment variable MAX_JOBS=N)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "[1/2] c++ -MMD -MF flatten_unflatten.o.d -DTORCH_EXTENSION_NAME=utils -DTORCH_API_INCLUDE_EXTENSION_H -DPYBIND11_COMPILER_TYPE=\\\"_gcc\\\" -DPYBIND11_STDLIB=\\\"_libstdcpp\\\" -DPYBIND11_BUILD_ABI=\\\"_cxxabi1011\\\" -isystem /usr/local/lib/python3.7/dist-packages/torch/include -isystem /usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include -isystem /usr/local/lib/python3.7/dist-packages/torch/include/TH -isystem /usr/local/lib/python3.7/dist-packages/torch/include/THC -isystem /usr/include/python3.7m -D_GLIBCXX_USE_CXX11_ABI=0 -fPIC -std=c++14 -c /usr/local/lib/python3.7/dist-packages/deepspeed/ops/csrc/utils/flatten_unflatten.cpp -o flatten_unflatten.o \n",
            "[2/2] c++ flatten_unflatten.o -shared -L/usr/local/lib/python3.7/dist-packages/torch/lib -lc10 -ltorch_cpu -ltorch -ltorch_python -o utils.so\n",
            "Loading extension module utils...\n",
            "Time to load utils op: 12.195115804672241 seconds\n",
            "[2021-03-25 02:37:30,886] [INFO] [stage2.py:130:__init__] Reduce bucket size 200000000.0\n",
            "[2021-03-25 02:37:30,886] [INFO] [stage2.py:131:__init__] Allgather bucket size 200000000.0\n",
            "[2021-03-25 02:37:30,886] [INFO] [stage2.py:132:__init__] CPU Offload: False\n",
            "[2021-03-25 02:37:31,542] [INFO] [stage2.py:399:__init__] optimizer state initialized\n",
            "[2021-03-25 02:37:31,543] [INFO] [logging.py:60:log_dist] [Rank 0] DeepSpeed Final Optimizer = adamw\n",
            "[2021-03-25 02:37:31,543] [INFO] [engine.py:439:_configure_lr_scheduler] DeepSpeed using configured LR scheduler = WarmupLR\n",
            "[2021-03-25 02:37:31,543] [INFO] [logging.py:60:log_dist] [Rank 0] DeepSpeed LR Scheduler = <deepspeed.runtime.lr_schedules.WarmupLR object at 0x7f9f00fef810>\n",
            "[2021-03-25 02:37:31,543] [INFO] [logging.py:60:log_dist] [Rank 0] step=0, skipped=0, lr=[3e-05], mom=[[0.9, 0.999]]\n",
            "[2021-03-25 02:37:31,543] [INFO] [config.py:737:print] DeepSpeedEngine configuration:\n",
            "[2021-03-25 02:37:31,544] [INFO] [config.py:741:print]   activation_checkpointing_config  {\n",
            "    \"contiguous_memory_optimization\": false,\n",
            "    \"cpu_checkpointing\": false,\n",
            "    \"number_checkpoints\": null,\n",
            "    \"partition_activations\": false,\n",
            "    \"profile\": false,\n",
            "    \"synchronize_checkpoint_boundary\": false\n",
            "}\n",
            "[2021-03-25 02:37:31,544] [INFO] [config.py:741:print]   allreduce_always_fp32 ........ False\n",
            "[2021-03-25 02:37:31,544] [INFO] [config.py:741:print]   amp_enabled .................. False\n",
            "[2021-03-25 02:37:31,544] [INFO] [config.py:741:print]   amp_params ................... False\n",
            "[2021-03-25 02:37:31,544] [INFO] [config.py:741:print]   checkpoint_tag_validation_enabled  True\n",
            "[2021-03-25 02:37:31,544] [INFO] [config.py:741:print]   checkpoint_tag_validation_fail  False\n",
            "[2021-03-25 02:37:31,544] [INFO] [config.py:741:print]   disable_allgather ............ False\n",
            "[2021-03-25 02:37:31,544] [INFO] [config.py:741:print]   dump_state ................... False\n",
            "[2021-03-25 02:37:31,544] [INFO] [config.py:741:print]   dynamic_loss_scale_args ...... {'init_scale': 65536, 'scale_window': 1000, 'delayed_shift': 2, 'min_scale': 1}\n",
            "[2021-03-25 02:37:31,544] [INFO] [config.py:741:print]   elasticity_enabled ........... False\n",
            "[2021-03-25 02:37:31,544] [INFO] [config.py:741:print]   flops_profiler_config ........ {\n",
            "    \"detailed\": true,\n",
            "    \"enabled\": false,\n",
            "    \"module_depth\": -1,\n",
            "    \"profile_step\": 1,\n",
            "    \"top_modules\": 3\n",
            "}\n",
            "[2021-03-25 02:37:31,544] [INFO] [config.py:741:print]   fp16_enabled ................. True\n",
            "[2021-03-25 02:37:31,544] [INFO] [config.py:741:print]   global_rank .................. 0\n",
            "[2021-03-25 02:37:31,544] [INFO] [config.py:741:print]   gradient_accumulation_steps .. 1\n",
            "[2021-03-25 02:37:31,545] [INFO] [config.py:741:print]   gradient_clipping ............ 1.0\n",
            "[2021-03-25 02:37:31,545] [INFO] [config.py:741:print]   gradient_predivide_factor .... 1.0\n",
            "[2021-03-25 02:37:31,545] [INFO] [config.py:741:print]   initial_dynamic_scale ........ 65536\n",
            "[2021-03-25 02:37:31,545] [INFO] [config.py:741:print]   loss_scale ................... 0\n",
            "[2021-03-25 02:37:31,545] [INFO] [config.py:741:print]   memory_breakdown ............. False\n",
            "[2021-03-25 02:37:31,545] [INFO] [config.py:741:print]   optimizer_legacy_fusion ...... False\n",
            "[2021-03-25 02:37:31,545] [INFO] [config.py:741:print]   optimizer_name ............... adamw\n",
            "[2021-03-25 02:37:31,545] [INFO] [config.py:741:print]   optimizer_params ............. {'lr': 3e-05, 'betas': [0.9, 0.999], 'eps': 1e-08, 'weight_decay': 3e-07}\n",
            "[2021-03-25 02:37:31,545] [INFO] [config.py:741:print]   pipeline ..................... {'stages': 'auto', 'partition': 'best', 'seed_layers': False, 'activation_checkpoint_interval': 0}\n",
            "[2021-03-25 02:37:31,545] [INFO] [config.py:741:print]   pld_enabled .................. False\n",
            "[2021-03-25 02:37:31,545] [INFO] [config.py:741:print]   pld_params ................... False\n",
            "[2021-03-25 02:37:31,545] [INFO] [config.py:741:print]   prescale_gradients ........... False\n",
            "[2021-03-25 02:37:31,545] [INFO] [config.py:741:print]   scheduler_name ............... WarmupLR\n",
            "[2021-03-25 02:37:31,545] [INFO] [config.py:741:print]   scheduler_params ............. {'warmup_min_lr': 0, 'warmup_max_lr': 3e-05, 'warmup_num_steps': 500}\n",
            "[2021-03-25 02:37:31,545] [INFO] [config.py:741:print]   sparse_attention ............. None\n",
            "[2021-03-25 02:37:31,545] [INFO] [config.py:741:print]   sparse_gradients_enabled ..... False\n",
            "[2021-03-25 02:37:31,545] [INFO] [config.py:741:print]   steps_per_print .............. 2000\n",
            "[2021-03-25 02:37:31,545] [INFO] [config.py:741:print]   tensorboard_enabled .......... False\n",
            "[2021-03-25 02:37:31,546] [INFO] [config.py:741:print]   tensorboard_job_name ......... DeepSpeedJobName\n",
            "[2021-03-25 02:37:31,546] [INFO] [config.py:741:print]   tensorboard_output_path ...... \n",
            "[2021-03-25 02:37:31,546] [INFO] [config.py:741:print]   train_batch_size ............. 16\n",
            "[2021-03-25 02:37:31,546] [INFO] [config.py:741:print]   train_micro_batch_size_per_gpu  16\n",
            "[2021-03-25 02:37:31,546] [INFO] [config.py:741:print]   wall_clock_breakdown ......... False\n",
            "[2021-03-25 02:37:31,546] [INFO] [config.py:741:print]   world_size ................... 1\n",
            "[2021-03-25 02:37:31,546] [INFO] [config.py:741:print]   zero_allow_untested_optimizer  False\n",
            "[2021-03-25 02:37:31,546] [INFO] [config.py:741:print]   zero_config .................. {\n",
            "    \"allgather_bucket_size\": 200000000.0,\n",
            "    \"allgather_partitions\": true,\n",
            "    \"contiguous_gradients\": true,\n",
            "    \"cpu_offload\": false,\n",
            "    \"cpu_offload_params\": false,\n",
            "    \"cpu_offload_use_pin_memory\": false,\n",
            "    \"elastic_checkpoint\": true,\n",
            "    \"load_from_fp32_weights\": true,\n",
            "    \"max_live_parameters\": 1000000000,\n",
            "    \"max_reuse_distance\": 1000000000,\n",
            "    \"overlap_comm\": true,\n",
            "    \"param_persistence_threshold\": 100000,\n",
            "    \"prefetch_bucket_size\": 50000000,\n",
            "    \"reduce_bucket_size\": 200000000.0,\n",
            "    \"reduce_scatter\": true,\n",
            "    \"stage\": 2,\n",
            "    \"sub_group_size\": 1000000000000\n",
            "}\n",
            "[2021-03-25 02:37:31,546] [INFO] [config.py:741:print]   zero_enabled ................. True\n",
            "[2021-03-25 02:37:31,546] [INFO] [config.py:741:print]   zero_optimization_stage ...... 2\n",
            "[2021-03-25 02:37:31,546] [INFO] [config.py:747:print]   json = {\n",
            "    \"fp16\":{\n",
            "        \"enabled\":true,\n",
            "        \"hysteresis\":2,\n",
            "        \"initial_scale_power\":16,\n",
            "        \"loss_scale\":0,\n",
            "        \"loss_scale_window\":1000,\n",
            "        \"min_loss_scale\":1\n",
            "    },\n",
            "    \"gradient_accumulation_steps\":1,\n",
            "    \"gradient_clipping\":1.0,\n",
            "    \"optimizer\":{\n",
            "        \"params\":{\n",
            "            \"betas\":[\n",
            "                0.9,\n",
            "                0.999\n",
            "            ],\n",
            "            \"eps\":1e-08,\n",
            "            \"lr\":3e-05,\n",
            "            \"weight_decay\":3e-07\n",
            "        },\n",
            "        \"type\":\"AdamW\"\n",
            "    },\n",
            "    \"scheduler\":{\n",
            "        \"params\":{\n",
            "            \"warmup_max_lr\":3e-05,\n",
            "            \"warmup_min_lr\":0,\n",
            "            \"warmup_num_steps\":500\n",
            "        },\n",
            "        \"type\":\"WarmupLR\"\n",
            "    },\n",
            "    \"steps_per_print\":2000,\n",
            "    \"train_micro_batch_size_per_gpu\":16,\n",
            "    \"wall_clock_breakdown\":false,\n",
            "    \"zero_optimization\":{\n",
            "        \"allgather_bucket_size\":200000000.0,\n",
            "        \"allgather_partitions\":true,\n",
            "        \"contiguous_gradients\":true,\n",
            "        \"cpu_offload\":false,\n",
            "        \"overlap_comm\":true,\n",
            "        \"reduce_bucket_size\":200000000.0,\n",
            "        \"reduce_scatter\":true,\n",
            "        \"stage\":2\n",
            "    }\n",
            "}\n",
            "Using /root/.cache/torch_extensions as PyTorch extensions root...\n",
            "No modifications detected for re-loaded extension module utils, skipping build step...\n",
            "Loading extension module utils...\n",
            "Time to load utils op: 0.0005977153778076172 seconds\n",
            "***** Running training *****\n",
            "  Num examples = 2000\n",
            "  Num Epochs = 1\n",
            "  Instantaneous batch size per device = 16\n",
            "  Total train batch size (w. parallel, distributed & accumulation) = 16\n",
            "  Gradient Accumulation steps = 1\n",
            "  Total optimization steps = 125\n",
            "2021-03-25 02:37:31.990754: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.11.0\n",
            "  0% 0/125 [00:00<?, ?it/s][2021-03-25 02:37:41,187] [INFO] [stage2.py:1391:step] [deepspeed] fp16 dynamic loss scale overflow! Rank 0 Skipping step. Attempted loss scale: 65536, reducing to 65536\n",
            "  1% 1/125 [00:05<11:43,  5.68s/it]tried to get lr value before scheduler/optimizer started stepping, returning lr=0\n",
            "{'loss': nan, 'learning_rate': 0, 'epoch': 0.01}\n",
            "  1% 1/125 [00:05<11:43,  5.68s/it][2021-03-25 02:37:41,383] [INFO] [stage2.py:1391:step] [deepspeed] fp16 dynamic loss scale overflow! Rank 0 Skipping step. Attempted loss scale: 65536, reducing to 32768.0\n",
            "  2% 2/125 [00:05<08:15,  4.03s/it][2021-03-25 02:37:41,579] [INFO] [stage2.py:1391:step] [deepspeed] fp16 dynamic loss scale overflow! Rank 0 Skipping step. Attempted loss scale: 32768.0, reducing to 16384.0\n",
            "  2% 3/125 [00:06<05:51,  2.88s/it][2021-03-25 02:37:41,866] [INFO] [stage2.py:1391:step] [deepspeed] fp16 dynamic loss scale overflow! Rank 0 Skipping step. Attempted loss scale: 16384.0, reducing to 8192.0\n",
            "  3% 4/125 [00:06<04:14,  2.10s/it][2021-03-25 02:37:42,106] [INFO] [stage2.py:1391:step] [deepspeed] fp16 dynamic loss scale overflow! Rank 0 Skipping step. Attempted loss scale: 8192.0, reducing to 4096.0\n",
            "  4% 5/125 [00:06<03:05,  1.54s/it][2021-03-25 02:37:42,322] [INFO] [stage2.py:1391:step] [deepspeed] fp16 dynamic loss scale overflow! Rank 0 Skipping step. Attempted loss scale: 4096.0, reducing to 2048.0\n",
            "  5% 6/125 [00:06<02:16,  1.15s/it][2021-03-25 02:37:42,507] [INFO] [stage2.py:1391:step] [deepspeed] fp16 dynamic loss scale overflow! Rank 0 Skipping step. Attempted loss scale: 2048.0, reducing to 1024.0\n",
            "  6% 7/125 [00:06<01:41,  1.17it/s][2021-03-25 02:37:42,703] [INFO] [stage2.py:1391:step] [deepspeed] fp16 dynamic loss scale overflow! Rank 0 Skipping step. Attempted loss scale: 1024.0, reducing to 512.0\n",
            "  6% 8/125 [00:07<01:17,  1.52it/s][2021-03-25 02:37:42,899] [INFO] [stage2.py:1391:step] [deepspeed] fp16 dynamic loss scale overflow! Rank 0 Skipping step. Attempted loss scale: 512.0, reducing to 256.0\n",
            "  7% 9/125 [00:07<01:00,  1.92it/s][2021-03-25 02:37:43,103] [INFO] [stage2.py:1391:step] [deepspeed] fp16 dynamic loss scale overflow! Rank 0 Skipping step. Attempted loss scale: 256.0, reducing to 128.0\n",
            "  8% 10/125 [00:07<00:48,  2.35it/s][2021-03-25 02:37:43,313] [INFO] [stage2.py:1391:step] [deepspeed] fp16 dynamic loss scale overflow! Rank 0 Skipping step. Attempted loss scale: 128.0, reducing to 64.0\n",
            " 10% 12/125 [00:08<00:40,  2.80it/s][2021-03-25 02:37:43,863] [INFO] [stage2.py:1391:step] [deepspeed] fp16 dynamic loss scale overflow! Rank 0 Skipping step. Attempted loss scale: 64.0, reducing to 32.0\n",
            " 10% 13/125 [00:08<00:34,  3.22it/s][2021-03-25 02:37:44,029] [INFO] [stage2.py:1391:step] [deepspeed] fp16 dynamic loss scale overflow! Rank 0 Skipping step. Attempted loss scale: 32.0, reducing to 16.0\n",
            " 13% 16/125 [00:09<00:28,  3.89it/s][2021-03-25 02:37:44,740] [INFO] [stage2.py:1391:step] [deepspeed] fp16 dynamic loss scale overflow! Rank 0 Skipping step. Attempted loss scale: 16.0, reducing to 8.0\n",
            " 21% 26/125 [00:11<00:26,  3.74it/s][2021-03-25 02:37:47,383] [INFO] [stage2.py:1391:step] [deepspeed] fp16 dynamic loss scale overflow! Rank 0 Skipping step. Attempted loss scale: 8.0, reducing to 4.0\n",
            " 43% 54/125 [00:19<00:19,  3.70it/s][2021-03-25 02:37:54,917] [INFO] [stage2.py:1391:step] [deepspeed] fp16 dynamic loss scale overflow! Rank 0 Skipping step. Attempted loss scale: 4.0, reducing to 2.0\n",
            " 70% 88/125 [00:28<00:09,  3.82it/s][2021-03-25 02:38:03,704] [INFO] [stage2.py:1391:step] [deepspeed] fp16 dynamic loss scale overflow! Rank 0 Skipping step. Attempted loss scale: 2.0, reducing to 1.0\n",
            "100% 125/125 [00:37<00:00,  3.54it/s]\n",
            "\n",
            "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
            "\n",
            "\n",
            "{'train_runtime': 41.963, 'train_samples_per_second': 2.979, 'epoch': 1.0}\n",
            "100% 125/125 [00:37<00:00,  3.29it/s]\n",
            "Saving model checkpoint to output_dir\n",
            "Configuration saved in output_dir/config.json\n",
            "Model weights saved in output_dir/pytorch_model.bin\n",
            "tokenizer config file saved in output_dir/tokenizer_config.json\n",
            "Special tokens file saved in output_dir/special_tokens_map.json\n",
            "Copy vocab file to output_dir/spiece.model\n",
            "***** train metrics *****\n",
            "  epoch                      =    1.0\n",
            "  init_mem_cpu_alloc_delta   =    2MB\n",
            "  init_mem_cpu_peaked_delta  =    0MB\n",
            "  init_mem_gpu_alloc_delta   =    0MB\n",
            "  init_mem_gpu_peaked_delta  =    0MB\n",
            "  train_mem_cpu_alloc_delta  =   79MB\n",
            "  train_mem_cpu_peaked_delta =    0MB\n",
            "  train_mem_gpu_alloc_delta  = 4010MB\n",
            "  train_mem_gpu_peaked_delta = 6553MB\n",
            "  train_runtime              = 41.963\n",
            "  train_samples              =   2000\n",
            "  train_samples_per_second   =  2.979\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GB1wFvII_MWB"
      },
      "source": [
        ""
      ],
      "execution_count": 9,
      "outputs": []
    }
  ]
}